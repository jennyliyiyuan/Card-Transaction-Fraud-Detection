{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has a wide variety of modeling algorithms for a binary classification problem. It reads a file creatd from a feaature selection process that has a reasonably small number of good variables. We can explore # ionput variables, model algorithms and tune model hyperparameters. ASt the end we can select our favorite algorithm, run it again and build the final model performace score percentile tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qyy/opt/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/qyy/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:369: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/Users/qyy/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:369: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/Users/qyy/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:369: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as XGBClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96397, 22)\n",
      "CPU times: user 123 ms, sys: 25.4 ms, total: 149 ms\n",
      "Wall time: 159 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_zip3_total_7</th>\n",
       "      <th>Merchnum_max_7</th>\n",
       "      <th>card_zip_total_14</th>\n",
       "      <th>card_zip_total_60</th>\n",
       "      <th>merch_zip_max_7</th>\n",
       "      <th>Card_Merchnum_desc_total_60</th>\n",
       "      <th>zip3_total_0</th>\n",
       "      <th>card_merch_total_30</th>\n",
       "      <th>card_zip_total_30</th>\n",
       "      <th>card_merch_total_60</th>\n",
       "      <th>...</th>\n",
       "      <th>amount_cat</th>\n",
       "      <th>Merchnum_desc_total_14</th>\n",
       "      <th>Card_Merchnum_desc_total_30</th>\n",
       "      <th>Card_Merchdesc_total_60</th>\n",
       "      <th>Merchnum_desc_max_7</th>\n",
       "      <th>merch_zip_total_0</th>\n",
       "      <th>zip3_actual/avg_60</th>\n",
       "      <th>Card_Merchdesc_total_7</th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>178.49</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>10.86</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>10.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.24</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   card_zip3_total_7  Merchnum_max_7  card_zip_total_14  card_zip_total_60  \\\n",
       "0               3.62            3.62               3.62               3.62   \n",
       "1              31.42           31.42              31.42              31.42   \n",
       "2             178.49          178.49             178.49             178.49   \n",
       "3               3.62            3.62               3.62               3.62   \n",
       "4               7.24            3.62               7.24               7.24   \n",
       "\n",
       "   merch_zip_max_7  Card_Merchnum_desc_total_60  zip3_total_0  \\\n",
       "0             3.62                         3.62          3.62   \n",
       "1            31.42                        31.42         31.42   \n",
       "2           178.49                       178.49        178.49   \n",
       "3             3.62                         3.62          7.24   \n",
       "4             3.62                         7.24         10.86   \n",
       "\n",
       "   card_merch_total_30  card_zip_total_30  card_merch_total_60  ...  \\\n",
       "0                 3.62               3.62                 3.62  ...   \n",
       "1                31.42              31.42                31.42  ...   \n",
       "2               178.49             178.49               178.49  ...   \n",
       "3                 3.62               3.62                 3.62  ...   \n",
       "4                 7.24               7.24                 7.24  ...   \n",
       "\n",
       "   amount_cat  Merchnum_desc_total_14  Card_Merchnum_desc_total_30  \\\n",
       "0           1                    3.62                         3.62   \n",
       "1           2                   31.42                        31.42   \n",
       "2           3                  178.49                       178.49   \n",
       "3           1                    3.62                         3.62   \n",
       "4           1                    7.24                         7.24   \n",
       "\n",
       "   Card_Merchdesc_total_60  Merchnum_desc_max_7  merch_zip_total_0  \\\n",
       "0                     3.62                 3.62               3.62   \n",
       "1                    31.42                31.42              31.42   \n",
       "2                   178.49               178.49             178.49   \n",
       "3                     3.62                 3.62               7.24   \n",
       "4                     7.24                 3.62              10.86   \n",
       "\n",
       "   zip3_actual/avg_60  Card_Merchdesc_total_7  Recnum  Fraud  \n",
       "0                 1.0                    3.62       1      0  \n",
       "1                 1.0                   31.42       2      0  \n",
       "2                 1.0                  178.49       3      0  \n",
       "3                 1.0                    3.62       4      0  \n",
       "4                 1.0                    7.24       5      0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "vars = pd.read_csv('vars_final 20 OK.csv')\n",
    "print(vars.shape)\n",
    "vars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>card_zip3_total_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Merchnum_max_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>card_zip_total_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>card_zip_total_60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>merch_zip_max_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Card_Merchnum_desc_total_60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zip3_total_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>card_merch_total_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>card_zip_total_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>card_merch_total_60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Merchnum_desc_total_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Merchnum_desc_avg_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>amount_cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Merchnum_desc_total_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Card_Merchnum_desc_total_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Card_Merchdesc_total_60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Merchnum_desc_max_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>merch_zip_total_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>zip3_actual/avg_60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Card_Merchdesc_total_7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  variable name\n",
       "0             card_zip3_total_7\n",
       "1                Merchnum_max_7\n",
       "2             card_zip_total_14\n",
       "3             card_zip_total_60\n",
       "4               merch_zip_max_7\n",
       "5   Card_Merchnum_desc_total_60\n",
       "6                  zip3_total_0\n",
       "7           card_merch_total_30\n",
       "8             card_zip_total_30\n",
       "9           card_merch_total_60\n",
       "10        Merchnum_desc_total_7\n",
       "11          Merchnum_desc_avg_7\n",
       "12                   amount_cat\n",
       "13       Merchnum_desc_total_14\n",
       "14  Card_Merchnum_desc_total_30\n",
       "15      Card_Merchdesc_total_60\n",
       "16          Merchnum_desc_max_7\n",
       "17            merch_zip_total_0\n",
       "18           zip3_actual/avg_60\n",
       "19       Card_Merchdesc_total_7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vars = pd.read_csv('final_vars_list 20 OK.csv')\n",
    "final_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Recnum',\n",
       " 'Fraud',\n",
       " 'card_zip3_total_7',\n",
       " 'Merchnum_max_7',\n",
       " 'card_zip_total_14',\n",
       " 'card_zip_total_60',\n",
       " 'merch_zip_max_7',\n",
       " 'Card_Merchnum_desc_total_60',\n",
       " 'zip3_total_0',\n",
       " 'card_merch_total_30',\n",
       " 'card_zip_total_30',\n",
       " 'card_merch_total_60',\n",
       " 'Merchnum_desc_total_7',\n",
       " 'Merchnum_desc_avg_7',\n",
       " 'amount_cat',\n",
       " 'Merchnum_desc_total_14',\n",
       " 'Card_Merchnum_desc_total_30']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.rename(columns={'recnum':'Recnum'},inplace=True)\n",
    "numvars = min(15,len(final_vars))\n",
    "final_vars_list = ['Recnum','Fraud']\n",
    "for i in range(numvars):\n",
    "    final_vars_list.append(final_vars.iloc[i]['variable name'])\n",
    "    \n",
    "final_vars_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>card_zip3_total_7</th>\n",
       "      <th>Merchnum_max_7</th>\n",
       "      <th>card_zip_total_14</th>\n",
       "      <th>card_zip_total_60</th>\n",
       "      <th>merch_zip_max_7</th>\n",
       "      <th>Card_Merchnum_desc_total_60</th>\n",
       "      <th>zip3_total_0</th>\n",
       "      <th>card_merch_total_30</th>\n",
       "      <th>card_zip_total_30</th>\n",
       "      <th>card_merch_total_60</th>\n",
       "      <th>Merchnum_desc_total_7</th>\n",
       "      <th>Merchnum_desc_avg_7</th>\n",
       "      <th>amount_cat</th>\n",
       "      <th>Merchnum_desc_total_14</th>\n",
       "      <th>Card_Merchnum_desc_total_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>2</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>3</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>10.86</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recnum  Fraud  card_zip3_total_7  Merchnum_max_7  card_zip_total_14  \\\n",
       "0       1      0               3.62            3.62               3.62   \n",
       "1       2      0              31.42           31.42              31.42   \n",
       "2       3      0             178.49          178.49             178.49   \n",
       "3       4      0               3.62            3.62               3.62   \n",
       "4       5      0               7.24            3.62               7.24   \n",
       "\n",
       "   card_zip_total_60  merch_zip_max_7  Card_Merchnum_desc_total_60  \\\n",
       "0               3.62             3.62                         3.62   \n",
       "1              31.42            31.42                        31.42   \n",
       "2             178.49           178.49                       178.49   \n",
       "3               3.62             3.62                         3.62   \n",
       "4               7.24             3.62                         7.24   \n",
       "\n",
       "   zip3_total_0  card_merch_total_30  card_zip_total_30  card_merch_total_60  \\\n",
       "0          3.62                 3.62               3.62                 3.62   \n",
       "1         31.42                31.42              31.42                31.42   \n",
       "2        178.49               178.49             178.49               178.49   \n",
       "3          7.24                 3.62               3.62                 3.62   \n",
       "4         10.86                 7.24               7.24                 7.24   \n",
       "\n",
       "   Merchnum_desc_total_7  Merchnum_desc_avg_7  amount_cat  \\\n",
       "0                   3.62                 3.62           1   \n",
       "1                  31.42                31.42           2   \n",
       "2                 178.49               178.49           3   \n",
       "3                   3.62                 3.62           1   \n",
       "4                   7.24                 3.62           1   \n",
       "\n",
       "   Merchnum_desc_total_14  Card_Merchnum_desc_total_30  \n",
       "0                    3.62                         3.62  \n",
       "1                   31.42                        31.42  \n",
       "2                  178.49                       178.49  \n",
       "3                    3.62                         3.62  \n",
       "4                    7.24                         7.24  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars = vars.filter(final_vars_list,axis=1)\n",
    "vars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96397, 17)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to cap variables. For some problems it helps\n",
    "Clip = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars.rename(columns={'fraud_label':'Fraud'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1059"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars['Fraud'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>card_zip3_total_7</th>\n",
       "      <th>Merchnum_max_7</th>\n",
       "      <th>card_zip_total_14</th>\n",
       "      <th>card_zip_total_60</th>\n",
       "      <th>merch_zip_max_7</th>\n",
       "      <th>Card_Merchnum_desc_total_60</th>\n",
       "      <th>zip3_total_0</th>\n",
       "      <th>card_merch_total_30</th>\n",
       "      <th>card_zip_total_30</th>\n",
       "      <th>card_merch_total_60</th>\n",
       "      <th>Merchnum_desc_total_7</th>\n",
       "      <th>Merchnum_desc_avg_7</th>\n",
       "      <th>amount_cat</th>\n",
       "      <th>Merchnum_desc_total_14</th>\n",
       "      <th>Card_Merchnum_desc_total_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>2</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>3</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>10.86</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>14.53</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>1</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.62</td>\n",
       "      <td>18.15</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>4</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>2</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10.86</td>\n",
       "      <td>3.67</td>\n",
       "      <td>10.86</td>\n",
       "      <td>10.86</td>\n",
       "      <td>3.67</td>\n",
       "      <td>10.86</td>\n",
       "      <td>21.77</td>\n",
       "      <td>10.86</td>\n",
       "      <td>10.86</td>\n",
       "      <td>10.86</td>\n",
       "      <td>10.86</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>10.86</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recnum  Fraud  card_zip3_total_7  Merchnum_max_7  card_zip_total_14  \\\n",
       "0       1      0               3.62            3.62               3.62   \n",
       "1       2      0              31.42           31.42              31.42   \n",
       "2       3      0             178.49          178.49             178.49   \n",
       "3       4      0               3.62            3.62               3.62   \n",
       "4       5      0               7.24            3.62               7.24   \n",
       "5       6      0               3.67            3.67               3.67   \n",
       "6       7      0               3.62            3.67               3.62   \n",
       "7       8      0             230.32          230.32             230.32   \n",
       "8       9      0              62.11           62.11              62.11   \n",
       "9      10      0              10.86            3.67              10.86   \n",
       "\n",
       "   card_zip_total_60  merch_zip_max_7  Card_Merchnum_desc_total_60  \\\n",
       "0               3.62             3.62                         3.62   \n",
       "1              31.42            31.42                        31.42   \n",
       "2             178.49           178.49                       178.49   \n",
       "3               3.62             3.62                         3.62   \n",
       "4               7.24             3.62                         7.24   \n",
       "5               3.67             3.67                         3.67   \n",
       "6               3.62             3.67                         3.62   \n",
       "7             230.32           230.32                       230.32   \n",
       "8              62.11            62.11                        62.11   \n",
       "9              10.86             3.67                        10.86   \n",
       "\n",
       "   zip3_total_0  card_merch_total_30  card_zip_total_30  card_merch_total_60  \\\n",
       "0          3.62                 3.62               3.62                 3.62   \n",
       "1         31.42                31.42              31.42                31.42   \n",
       "2        178.49               178.49             178.49               178.49   \n",
       "3          7.24                 3.62               3.62                 3.62   \n",
       "4         10.86                 7.24               7.24                 7.24   \n",
       "5         14.53                 3.67               3.67                 3.67   \n",
       "6         18.15                 3.62               3.62                 3.62   \n",
       "7        230.32               230.32             230.32               230.32   \n",
       "8         62.11                62.11              62.11                62.11   \n",
       "9         21.77                10.86              10.86                10.86   \n",
       "\n",
       "   Merchnum_desc_total_7  Merchnum_desc_avg_7  amount_cat  \\\n",
       "0                   3.62                 3.62           1   \n",
       "1                  31.42                31.42           2   \n",
       "2                 178.49               178.49           3   \n",
       "3                   3.62                 3.62           1   \n",
       "4                   7.24                 3.62           1   \n",
       "5                   3.67                 3.67           1   \n",
       "6                   7.24                 3.62           1   \n",
       "7                 230.32               230.32           4   \n",
       "8                  62.11                62.11           2   \n",
       "9                  10.86                 3.62           1   \n",
       "\n",
       "   Merchnum_desc_total_14  Card_Merchnum_desc_total_30  \n",
       "0                    3.62                         3.62  \n",
       "1                   31.42                        31.42  \n",
       "2                  178.49                       178.49  \n",
       "3                    3.62                         3.62  \n",
       "4                    7.24                         7.24  \n",
       "5                    3.67                         3.67  \n",
       "6                    7.24                         3.62  \n",
       "7                  230.32                       230.32  \n",
       "8                   62.11                        62.11  \n",
       "9                   10.86                        10.86  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96397, 17)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>card_zip3_total_7</th>\n",
       "      <th>Merchnum_max_7</th>\n",
       "      <th>card_zip_total_14</th>\n",
       "      <th>card_zip_total_60</th>\n",
       "      <th>merch_zip_max_7</th>\n",
       "      <th>Card_Merchnum_desc_total_60</th>\n",
       "      <th>zip3_total_0</th>\n",
       "      <th>card_merch_total_30</th>\n",
       "      <th>card_zip_total_30</th>\n",
       "      <th>card_merch_total_60</th>\n",
       "      <th>Merchnum_desc_total_7</th>\n",
       "      <th>Merchnum_desc_avg_7</th>\n",
       "      <th>amount_cat</th>\n",
       "      <th>Merchnum_desc_total_14</th>\n",
       "      <th>Card_Merchnum_desc_total_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.0000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48365.481820</td>\n",
       "      <td>0.010986</td>\n",
       "      <td>766.708755</td>\n",
       "      <td>811.760529</td>\n",
       "      <td>806.656625</td>\n",
       "      <td>1266.636330</td>\n",
       "      <td>810.781862</td>\n",
       "      <td>1086.172428</td>\n",
       "      <td>1385.252825</td>\n",
       "      <td>922.819733</td>\n",
       "      <td>992.1012</td>\n",
       "      <td>1141.217228</td>\n",
       "      <td>2254.087053</td>\n",
       "      <td>396.376864</td>\n",
       "      <td>2.999222</td>\n",
       "      <td>3629.081765</td>\n",
       "      <td>886.797254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27945.003883</td>\n",
       "      <td>0.104236</td>\n",
       "      <td>4137.374620</td>\n",
       "      <td>1342.561234</td>\n",
       "      <td>4186.923501</td>\n",
       "      <td>4651.346596</td>\n",
       "      <td>1342.127110</td>\n",
       "      <td>4546.365935</td>\n",
       "      <td>3305.170073</td>\n",
       "      <td>4298.907440</td>\n",
       "      <td>4346.6019</td>\n",
       "      <td>4551.733037</td>\n",
       "      <td>6299.460682</td>\n",
       "      <td>697.750999</td>\n",
       "      <td>1.414452</td>\n",
       "      <td>8698.384382</td>\n",
       "      <td>4291.154066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24154.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.150000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>132.530000</td>\n",
       "      <td>124.880000</td>\n",
       "      <td>68.820000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>93.790000</td>\n",
       "      <td>105.7500</td>\n",
       "      <td>108.810000</td>\n",
       "      <td>130.350000</td>\n",
       "      <td>55.970000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>160.900000</td>\n",
       "      <td>61.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48365.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>238.200000</td>\n",
       "      <td>389.970000</td>\n",
       "      <td>257.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>389.000000</td>\n",
       "      <td>277.670000</td>\n",
       "      <td>545.750000</td>\n",
       "      <td>289.680000</td>\n",
       "      <td>322.7800</td>\n",
       "      <td>348.790000</td>\n",
       "      <td>502.820000</td>\n",
       "      <td>205.450000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>699.940000</td>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>72578.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>693.560000</td>\n",
       "      <td>1131.400000</td>\n",
       "      <td>718.640000</td>\n",
       "      <td>1178.840000</td>\n",
       "      <td>1128.960000</td>\n",
       "      <td>933.000000</td>\n",
       "      <td>1630.710000</td>\n",
       "      <td>824.680000</td>\n",
       "      <td>906.2700</td>\n",
       "      <td>1023.040000</td>\n",
       "      <td>2137.500000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3267.950000</td>\n",
       "      <td>780.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96753.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>217467.180000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>306633.4100</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>313984.550000</td>\n",
       "      <td>28392.840000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>319334.680000</td>\n",
       "      <td>306633.410000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Recnum         Fraud  card_zip3_total_7  Merchnum_max_7  \\\n",
       "count  96397.000000  96397.000000       96397.000000    96397.000000   \n",
       "mean   48365.481820      0.010986         766.708755      811.760529   \n",
       "std    27945.003883      0.104236        4137.374620     1342.561234   \n",
       "min        1.000000      0.000000           0.010000        0.010000   \n",
       "25%    24154.000000      0.000000          77.150000      125.000000   \n",
       "50%    48365.000000      0.000000         238.200000      389.970000   \n",
       "75%    72578.000000      0.000000         693.560000     1131.400000   \n",
       "max    96753.000000      1.000000      306633.410000    47900.000000   \n",
       "\n",
       "       card_zip_total_14  card_zip_total_60  merch_zip_max_7  \\\n",
       "count       96397.000000       96397.000000     96397.000000   \n",
       "mean          806.656625        1266.636330       810.781862   \n",
       "std          4186.923501        4651.346596      1342.127110   \n",
       "min             0.010000           0.010000         0.010000   \n",
       "25%            85.000000         132.530000       124.880000   \n",
       "50%           257.000000         410.000000       389.000000   \n",
       "75%           718.640000        1178.840000      1128.960000   \n",
       "max        306633.410000      306633.410000     47900.000000   \n",
       "\n",
       "       Card_Merchnum_desc_total_60   zip3_total_0  card_merch_total_30  \\\n",
       "count                 96397.000000   96397.000000         96397.000000   \n",
       "mean                   1086.172428    1385.252825           922.819733   \n",
       "std                    4546.365935    3305.170073          4298.907440   \n",
       "min                       0.010000       0.010000             0.010000   \n",
       "25%                      68.820000     169.000000            93.790000   \n",
       "50%                     277.670000     545.750000           289.680000   \n",
       "75%                     933.000000    1630.710000           824.680000   \n",
       "max                  306633.410000  217467.180000        306633.410000   \n",
       "\n",
       "       card_zip_total_30  card_merch_total_60  Merchnum_desc_total_7  \\\n",
       "count         96397.0000         96397.000000           96397.000000   \n",
       "mean            992.1012          1141.217228            2254.087053   \n",
       "std            4346.6019          4551.733037            6299.460682   \n",
       "min               0.0100             0.010000               0.010000   \n",
       "25%             105.7500           108.810000             130.350000   \n",
       "50%             322.7800           348.790000             502.820000   \n",
       "75%             906.2700          1023.040000            2137.500000   \n",
       "max          306633.4100        306633.410000          313984.550000   \n",
       "\n",
       "       Merchnum_desc_avg_7    amount_cat  Merchnum_desc_total_14  \\\n",
       "count         96397.000000  96397.000000            96397.000000   \n",
       "mean            396.376864      2.999222             3629.081765   \n",
       "std             697.750999      1.414452             8698.384382   \n",
       "min               0.010000      1.000000                0.010000   \n",
       "25%              55.970000      2.000000              160.900000   \n",
       "50%             205.450000      3.000000              699.940000   \n",
       "75%             481.000000      4.000000             3267.950000   \n",
       "max           28392.840000      5.000000           319334.680000   \n",
       "\n",
       "       Card_Merchnum_desc_total_30  \n",
       "count                 96397.000000  \n",
       "mean                    886.797254  \n",
       "std                    4291.154066  \n",
       "min                       0.010000  \n",
       "25%                      61.940000  \n",
       "50%                     240.000000  \n",
       "75%                     780.000000  \n",
       "max                  306633.410000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fraud\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_save = vars['Recnum']\n",
    "Y_save = pd.DataFrame(vars.loc[:,'Fraud'])\n",
    "Y_save.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale and truncate field values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_zip3_total_7</th>\n",
       "      <th>Merchnum_max_7</th>\n",
       "      <th>card_zip_total_14</th>\n",
       "      <th>card_zip_total_60</th>\n",
       "      <th>merch_zip_max_7</th>\n",
       "      <th>Card_Merchnum_desc_total_60</th>\n",
       "      <th>zip3_total_0</th>\n",
       "      <th>card_merch_total_30</th>\n",
       "      <th>card_zip_total_30</th>\n",
       "      <th>card_merch_total_60</th>\n",
       "      <th>Merchnum_desc_total_7</th>\n",
       "      <th>Merchnum_desc_avg_7</th>\n",
       "      <th>amount_cat</th>\n",
       "      <th>Merchnum_desc_total_14</th>\n",
       "      <th>Card_Merchnum_desc_total_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.0000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>766.708755</td>\n",
       "      <td>811.760529</td>\n",
       "      <td>806.656625</td>\n",
       "      <td>1266.636330</td>\n",
       "      <td>810.781862</td>\n",
       "      <td>1086.172428</td>\n",
       "      <td>1385.252825</td>\n",
       "      <td>922.819733</td>\n",
       "      <td>992.1012</td>\n",
       "      <td>1141.217228</td>\n",
       "      <td>2254.087053</td>\n",
       "      <td>396.376864</td>\n",
       "      <td>2.999222</td>\n",
       "      <td>3629.081765</td>\n",
       "      <td>886.797254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4137.374620</td>\n",
       "      <td>1342.561234</td>\n",
       "      <td>4186.923501</td>\n",
       "      <td>4651.346596</td>\n",
       "      <td>1342.127110</td>\n",
       "      <td>4546.365935</td>\n",
       "      <td>3305.170073</td>\n",
       "      <td>4298.907440</td>\n",
       "      <td>4346.6019</td>\n",
       "      <td>4551.733037</td>\n",
       "      <td>6299.460682</td>\n",
       "      <td>697.750999</td>\n",
       "      <td>1.414452</td>\n",
       "      <td>8698.384382</td>\n",
       "      <td>4291.154066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>77.150000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>132.530000</td>\n",
       "      <td>124.880000</td>\n",
       "      <td>68.820000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>93.790000</td>\n",
       "      <td>105.7500</td>\n",
       "      <td>108.810000</td>\n",
       "      <td>130.350000</td>\n",
       "      <td>55.970000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>160.900000</td>\n",
       "      <td>61.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>238.200000</td>\n",
       "      <td>389.970000</td>\n",
       "      <td>257.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>389.000000</td>\n",
       "      <td>277.670000</td>\n",
       "      <td>545.750000</td>\n",
       "      <td>289.680000</td>\n",
       "      <td>322.7800</td>\n",
       "      <td>348.790000</td>\n",
       "      <td>502.820000</td>\n",
       "      <td>205.450000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>699.940000</td>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>693.560000</td>\n",
       "      <td>1131.400000</td>\n",
       "      <td>718.640000</td>\n",
       "      <td>1178.840000</td>\n",
       "      <td>1128.960000</td>\n",
       "      <td>933.000000</td>\n",
       "      <td>1630.710000</td>\n",
       "      <td>824.680000</td>\n",
       "      <td>906.2700</td>\n",
       "      <td>1023.040000</td>\n",
       "      <td>2137.500000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3267.950000</td>\n",
       "      <td>780.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>306633.410000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>217467.180000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>306633.4100</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>313984.550000</td>\n",
       "      <td>28392.840000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>319334.680000</td>\n",
       "      <td>306633.410000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       card_zip3_total_7  Merchnum_max_7  card_zip_total_14  \\\n",
       "count       96397.000000    96397.000000       96397.000000   \n",
       "mean          766.708755      811.760529         806.656625   \n",
       "std          4137.374620     1342.561234        4186.923501   \n",
       "min             0.010000        0.010000           0.010000   \n",
       "25%            77.150000      125.000000          85.000000   \n",
       "50%           238.200000      389.970000         257.000000   \n",
       "75%           693.560000     1131.400000         718.640000   \n",
       "max        306633.410000    47900.000000      306633.410000   \n",
       "\n",
       "       card_zip_total_60  merch_zip_max_7  Card_Merchnum_desc_total_60  \\\n",
       "count       96397.000000     96397.000000                 96397.000000   \n",
       "mean         1266.636330       810.781862                  1086.172428   \n",
       "std          4651.346596      1342.127110                  4546.365935   \n",
       "min             0.010000         0.010000                     0.010000   \n",
       "25%           132.530000       124.880000                    68.820000   \n",
       "50%           410.000000       389.000000                   277.670000   \n",
       "75%          1178.840000      1128.960000                   933.000000   \n",
       "max        306633.410000     47900.000000                306633.410000   \n",
       "\n",
       "        zip3_total_0  card_merch_total_30  card_zip_total_30  \\\n",
       "count   96397.000000         96397.000000         96397.0000   \n",
       "mean     1385.252825           922.819733           992.1012   \n",
       "std      3305.170073          4298.907440          4346.6019   \n",
       "min         0.010000             0.010000             0.0100   \n",
       "25%       169.000000            93.790000           105.7500   \n",
       "50%       545.750000           289.680000           322.7800   \n",
       "75%      1630.710000           824.680000           906.2700   \n",
       "max    217467.180000        306633.410000        306633.4100   \n",
       "\n",
       "       card_merch_total_60  Merchnum_desc_total_7  Merchnum_desc_avg_7  \\\n",
       "count         96397.000000           96397.000000         96397.000000   \n",
       "mean           1141.217228            2254.087053           396.376864   \n",
       "std            4551.733037            6299.460682           697.750999   \n",
       "min               0.010000               0.010000             0.010000   \n",
       "25%             108.810000             130.350000            55.970000   \n",
       "50%             348.790000             502.820000           205.450000   \n",
       "75%            1023.040000            2137.500000           481.000000   \n",
       "max          306633.410000          313984.550000         28392.840000   \n",
       "\n",
       "         amount_cat  Merchnum_desc_total_14  Card_Merchnum_desc_total_30  \n",
       "count  96397.000000            96397.000000                 96397.000000  \n",
       "mean       2.999222             3629.081765                   886.797254  \n",
       "std        1.414452             8698.384382                  4291.154066  \n",
       "min        1.000000                0.010000                     0.010000  \n",
       "25%        2.000000              160.900000                    61.940000  \n",
       "50%        3.000000              699.940000                   240.000000  \n",
       "75%        4.000000             3267.950000                   780.000000  \n",
       "max        5.000000           319334.680000                306633.410000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_no_scaling = vars.drop(columns = ['Recnum','Fraud'])\n",
    "X_no_scaling.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = (X_no_scaling - X_no_scaling.mean()) / X_no_scaling.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_zip3_total_7</th>\n",
       "      <th>Merchnum_max_7</th>\n",
       "      <th>card_zip_total_14</th>\n",
       "      <th>card_zip_total_60</th>\n",
       "      <th>merch_zip_max_7</th>\n",
       "      <th>Card_Merchnum_desc_total_60</th>\n",
       "      <th>zip3_total_0</th>\n",
       "      <th>card_merch_total_30</th>\n",
       "      <th>card_zip_total_30</th>\n",
       "      <th>card_merch_total_60</th>\n",
       "      <th>Merchnum_desc_total_7</th>\n",
       "      <th>Merchnum_desc_avg_7</th>\n",
       "      <th>amount_cat</th>\n",
       "      <th>Merchnum_desc_total_14</th>\n",
       "      <th>Card_Merchnum_desc_total_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>9.639700e+04</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.012382</td>\n",
       "      <td>-0.009205</td>\n",
       "      <td>-0.012245</td>\n",
       "      <td>-0.010559</td>\n",
       "      <td>-0.009214</td>\n",
       "      <td>-0.010953</td>\n",
       "      <td>-0.009276</td>\n",
       "      <td>-0.011740</td>\n",
       "      <td>-0.011516</td>\n",
       "      <td>-0.010922</td>\n",
       "      <td>-0.009980</td>\n",
       "      <td>-0.007535</td>\n",
       "      <td>7.012244e-15</td>\n",
       "      <td>-0.007894</td>\n",
       "      <td>-0.011781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.477940</td>\n",
       "      <td>0.851103</td>\n",
       "      <td>0.496200</td>\n",
       "      <td>0.631814</td>\n",
       "      <td>0.850917</td>\n",
       "      <td>0.606050</td>\n",
       "      <td>0.716087</td>\n",
       "      <td>0.537816</td>\n",
       "      <td>0.554095</td>\n",
       "      <td>0.607794</td>\n",
       "      <td>0.714933</td>\n",
       "      <td>0.848842</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.823226</td>\n",
       "      <td>0.534859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.185310</td>\n",
       "      <td>-0.604628</td>\n",
       "      <td>-0.192659</td>\n",
       "      <td>-0.272314</td>\n",
       "      <td>-0.604095</td>\n",
       "      <td>-0.238908</td>\n",
       "      <td>-0.419114</td>\n",
       "      <td>-0.214661</td>\n",
       "      <td>-0.228245</td>\n",
       "      <td>-0.250719</td>\n",
       "      <td>-0.357821</td>\n",
       "      <td>-0.568063</td>\n",
       "      <td>-1.413425e+00</td>\n",
       "      <td>-0.417212</td>\n",
       "      <td>-0.206655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.166666</td>\n",
       "      <td>-0.511530</td>\n",
       "      <td>-0.172360</td>\n",
       "      <td>-0.243823</td>\n",
       "      <td>-0.511056</td>\n",
       "      <td>-0.223773</td>\n",
       "      <td>-0.367985</td>\n",
       "      <td>-0.192847</td>\n",
       "      <td>-0.203918</td>\n",
       "      <td>-0.226816</td>\n",
       "      <td>-0.337130</td>\n",
       "      <td>-0.487863</td>\n",
       "      <td>-7.064377e-01</td>\n",
       "      <td>-0.398716</td>\n",
       "      <td>-0.192223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.127740</td>\n",
       "      <td>-0.314169</td>\n",
       "      <td>-0.131279</td>\n",
       "      <td>-0.184170</td>\n",
       "      <td>-0.314264</td>\n",
       "      <td>-0.177835</td>\n",
       "      <td>-0.253997</td>\n",
       "      <td>-0.147279</td>\n",
       "      <td>-0.153987</td>\n",
       "      <td>-0.174094</td>\n",
       "      <td>-0.278003</td>\n",
       "      <td>-0.273632</td>\n",
       "      <td>5.500594e-04</td>\n",
       "      <td>-0.336745</td>\n",
       "      <td>-0.150728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.017680</td>\n",
       "      <td>0.238082</td>\n",
       "      <td>-0.021022</td>\n",
       "      <td>-0.018875</td>\n",
       "      <td>0.237070</td>\n",
       "      <td>-0.033691</td>\n",
       "      <td>0.074265</td>\n",
       "      <td>-0.022829</td>\n",
       "      <td>-0.019747</td>\n",
       "      <td>-0.025963</td>\n",
       "      <td>-0.018507</td>\n",
       "      <td>0.121280</td>\n",
       "      <td>7.075378e-01</td>\n",
       "      <td>-0.041517</td>\n",
       "      <td>-0.024888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.414525e+00</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       card_zip3_total_7  Merchnum_max_7  card_zip_total_14  \\\n",
       "count       96397.000000    96397.000000       96397.000000   \n",
       "mean           -0.012382       -0.009205          -0.012245   \n",
       "std             0.477940        0.851103           0.496200   \n",
       "min            -0.185310       -0.604628          -0.192659   \n",
       "25%            -0.166666       -0.511530          -0.172360   \n",
       "50%            -0.127740       -0.314169          -0.131279   \n",
       "75%            -0.017680        0.238082          -0.021022   \n",
       "max            10.000000       10.000000          10.000000   \n",
       "\n",
       "       card_zip_total_60  merch_zip_max_7  Card_Merchnum_desc_total_60  \\\n",
       "count       96397.000000     96397.000000                 96397.000000   \n",
       "mean           -0.010559        -0.009214                    -0.010953   \n",
       "std             0.631814         0.850917                     0.606050   \n",
       "min            -0.272314        -0.604095                    -0.238908   \n",
       "25%            -0.243823        -0.511056                    -0.223773   \n",
       "50%            -0.184170        -0.314264                    -0.177835   \n",
       "75%            -0.018875         0.237070                    -0.033691   \n",
       "max            10.000000        10.000000                    10.000000   \n",
       "\n",
       "       zip3_total_0  card_merch_total_30  card_zip_total_30  \\\n",
       "count  96397.000000         96397.000000       96397.000000   \n",
       "mean      -0.009276            -0.011740          -0.011516   \n",
       "std        0.716087             0.537816           0.554095   \n",
       "min       -0.419114            -0.214661          -0.228245   \n",
       "25%       -0.367985            -0.192847          -0.203918   \n",
       "50%       -0.253997            -0.147279          -0.153987   \n",
       "75%        0.074265            -0.022829          -0.019747   \n",
       "max       10.000000            10.000000          10.000000   \n",
       "\n",
       "       card_merch_total_60  Merchnum_desc_total_7  Merchnum_desc_avg_7  \\\n",
       "count         96397.000000           96397.000000         96397.000000   \n",
       "mean             -0.010922              -0.009980            -0.007535   \n",
       "std               0.607794               0.714933             0.848842   \n",
       "min              -0.250719              -0.357821            -0.568063   \n",
       "25%              -0.226816              -0.337130            -0.487863   \n",
       "50%              -0.174094              -0.278003            -0.273632   \n",
       "75%              -0.025963              -0.018507             0.121280   \n",
       "max              10.000000              10.000000            10.000000   \n",
       "\n",
       "         amount_cat  Merchnum_desc_total_14  Card_Merchnum_desc_total_30  \n",
       "count  9.639700e+04            96397.000000                 96397.000000  \n",
       "mean   7.012244e-15               -0.007894                    -0.011781  \n",
       "std    1.000000e+00                0.823226                     0.534859  \n",
       "min   -1.413425e+00               -0.417212                    -0.206655  \n",
       "25%   -7.064377e-01               -0.398716                    -0.192223  \n",
       "50%    5.500594e-04               -0.336745                    -0.150728  \n",
       "75%    7.075378e-01               -0.041517                    -0.024888  \n",
       "max    1.414525e+00               10.000000                    10.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# push in any outlier values\n",
    "cols = X.columns\n",
    "X.loc[:,cols] = X[cols].clip(upper=Clip)\n",
    "X.loc[:,cols] = X[cols].clip(lower=-1*Clip)\n",
    "# X = (X_no_scaling - X_no_scaling.mean()) / X_no_scaling.std()\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# separate data into modeling (traintest) and out of time\n",
    "oot_recnum=84300\n",
    "X_trntst = X[0:oot_recnum]\n",
    "Y_trntst = Y_save[0:oot_recnum]\n",
    "X_oot = X[oot_recnum:]\n",
    "Y_oot = Y_save[oot_recnum:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "niter = 0\n",
    "nitermax = 10\n",
    "X_oot_orig = X_oot.copy()\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve a linear regression with ridge and lass regularization and watch how the variable weights evolve with the regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV \n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(7,-2,100)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 15)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "coefs = []\n",
    "for a in alphas: \n",
    "    ridge.set_params(alpha=a) \n",
    "    ridge.fit(X_trn,Y_trn.values.ravel()) \n",
    "    coefs.append(ridge.coef_) \n",
    "np.shape(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Ridge')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ax = plt.gca() # Get the current Axes instance\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('alpha') \n",
    "plt.ylabel('standadized coef') \n",
    "plt.title('Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(2,-8,100)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qyy/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.497e-02, tolerance: 6.115e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/qyy/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e-01, tolerance: 6.115e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/qyy/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.913e-01, tolerance: 6.115e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/qyy/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.029e-01, tolerance: 6.115e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/qyy/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.767e-01, tolerance: 6.115e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/qyy/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.456e-01, tolerance: 6.115e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/qyy/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.158e+00, tolerance: 6.115e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/qyy/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.783e+00, tolerance: 6.115e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/qyy/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.720e+00, tolerance: 6.115e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['Recnum', 'Fraud', 'card_zip3_total_7', 'Merchnum_max_7', 'card_zip_total_14', 'card_zip_total_60', 'merch_zip_max_7', 'Card_Merchnum_desc_total_60', 'zip3_total_0', 'card_merch_total_30', 'card_zip_total_30', 'card_merch_total_60', 'Merchnum_desc_total_7', 'Merchnum_desc_avg_7', 'amount_cat']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qyy/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.102e+00, tolerance: 6.115e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# sometimes this cell takes a long time\n",
    "lasso = Lasso(max_iter=10000) \n",
    "coefs = [] \n",
    "for a in alphas: \n",
    "    lasso.set_params(alpha=a) \n",
    "    lasso.fit(X_trn,Y_trn.values.ravel()) \n",
    "    coefs.append(lasso.coef_) \n",
    "# print('Shape:',np.shape(coefs)\n",
    "print('Selected Features:', list(vars.columns[np.where(lasso.coef_!=0)[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fbb23a956d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ax = plt.gca() # Get the current Axes instance \n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('standerdized coef') \n",
    "plt.title('Lasso')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can comment out any of these model cells and just explore one model type. You can also just rerun that single cell multiple times as you explore different model hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modeling_output = pd.DataFrame(columns=['Model','Trn','Tst','OOT'],index=range(1000))\n",
    "counter = 0\n",
    "model_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "penalty='none' is not supported for the liblinear solver",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:13\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1461\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1432\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1433\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1434\u001b[0m \u001b[38;5;124;03m    Fit the model according to the given training data.\u001b[39;00m\n\u001b[1;32m   1435\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1459\u001b[0m \u001b[38;5;124;03m    The SAGA solver supports both float64 and float32 bit arrays.\u001b[39;00m\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1461\u001b[0m     solver \u001b[38;5;241m=\u001b[39m \u001b[43m_check_solver\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC, numbers\u001b[38;5;241m.\u001b[39mNumber) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1464\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPenalty term must be positive; got (C=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:464\u001b[0m, in \u001b[0;36m_check_solver\u001b[0;34m(solver, penalty, dual)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m solver supports elasticnet penalty, got solver=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    459\u001b[0m             solver\n\u001b[1;32m    460\u001b[0m         )\n\u001b[1;32m    461\u001b[0m     )\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m penalty \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 464\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpenalty=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported for the liblinear solver\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solver\n",
      "\u001b[0;31mValueError\u001b[0m: penalty='none' is not supported for the liblinear solver"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Logistic regression\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = LogisticRegression(penalty = 'none', max_iter=1000)\n",
    " \n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['log reg',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7332268370607029 0.6889763779527559 0.4860335195530726\n",
      "1 0.7203252032520325 0.6981132075471698 0.3575418994413408\n",
      "2 0.7230273752012882 0.7142857142857143 0.49162011173184356\n",
      "3 0.7259842519685039 0.7061224489795919 0.5698324022346368\n",
      "4 0.7764705882352941 0.6947368421052632 0.5307262569832403\n",
      "5 0.7114427860696517 0.6787003610108303 0.5027932960893855\n",
      "6 0.7140468227424749 0.6773049645390071 0.5307262569832403\n",
      "7 0.747557003257329 0.6578947368421053 0.5642458100558659\n",
      "8 0.7218649517684887 0.689922480620155 0.5363128491620112\n",
      "9 0.7479270315091211 0.6787003610108303 0.547486033519553\n",
      "trn    0.732187\n",
      "tst    0.688476\n",
      "oot    0.511732\n",
      "dtype: float64\n",
      "CPU times: user 7.69 s, sys: 45.1 ms, total: 7.73 s\n",
      "Wall time: 7.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Single DT\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = DecisionTreeClassifier(splitter = 'best', criterion = 'gini', max_depth=None, min_samples_split=600,min_samples_leaf=50, max_features = 15)\n",
    " \n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['DT',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "\n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8118971061093248 0.7286821705426356 0.5418994413407822\n",
      "1 0.7996715927750411 0.7343173431734318 0.5418994413407822\n",
      "2 0.8040752351097179 0.7892561983471075 0.5586592178770949\n",
      "3 0.7835703001579779 0.7489878542510121 0.553072625698324\n",
      "4 0.8003300330033003 0.7773722627737226 0.547486033519553\n",
      "5 0.8063439065108514 0.7224199288256228 0.547486033519553\n",
      "6 0.8208 0.7176470588235294 0.5418994413407822\n",
      "7 0.8023255813953488 0.7517985611510791 0.547486033519553\n",
      "8 0.8073836276083467 0.7509727626459144 0.5586592178770949\n",
      "9 0.8137715179968701 0.7344398340248963 0.5251396648044693\n",
      "trn    0.805017\n",
      "tst    0.745589\n",
      "oot    0.546369\n",
      "dtype: float64\n",
      "CPU times: user 1min 38s, sys: 346 ms, total: 1min 38s\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# RF\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=80,max_depth=8,min_samples_split=80,min_samples_leaf=50,max_features=5, bootstrap=True)\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['RF',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8581081081081081 0.8055555555555556 0.5754189944134078\n",
      "1 0.8676470588235294 0.8097014925373134 0.5586592178770949\n",
      "2 0.847723704866562 0.8436213991769548 0.5418994413407822\n",
      "3 0.8543371522094927 0.7434944237918215 0.5642458100558659\n",
      "4 0.8643790849673203 0.7985074626865671 0.5586592178770949\n",
      "5 0.8508196721311475 0.8518518518518519 0.5586592178770949\n",
      "6 0.8741830065359477 0.7649253731343284 0.5642458100558659\n",
      "7 0.8528951486697965 0.8215767634854771 0.5698324022346368\n",
      "8 0.8580750407830342 0.7827715355805244 0.5642458100558659\n",
      "9 0.8444055944055944 0.7922077922077922 0.5698324022346368\n",
      "trn    0.857257\n",
      "tst    0.801421\n",
      "oot    0.562570\n",
      "dtype: float64\n",
      "CPU times: user 46.1 s, sys: 416 ms, total: 46.6 s\n",
      "Wall time: 5.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# LGBM\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = lgb.LGBMClassifier(num_leaves=3,n_estimators=600)\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter,'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter,'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter,'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['LGBM',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7321711568938193 0.751004016064257 0.5418994413407822\n",
      "1 0.7330097087378641 0.7748091603053435 0.5418994413407822\n",
      "2 0.7507936507936508 0.72 0.5418994413407822\n",
      "3 0.7429048414023373 0.7224199288256228 0.5418994413407822\n",
      "4 0.734375 0.7666666666666667 0.5418994413407822\n",
      "5 0.7708333333333334 0.68359375 0.5363128491620112\n",
      "6 0.7576736672051696 0.7203065134099617 0.5418994413407822\n",
      "7 0.7348242811501597 0.7440944881889764 0.5418994413407822\n",
      "8 0.7455716586151369 0.7297297297297297 0.5363128491620112\n",
      "9 0.7314662273476112 0.7582417582417582 0.5418994413407822\n",
      "trn    0.743362\n",
      "tst    0.737087\n",
      "oot    0.540782\n",
      "dtype: float64\n",
      "CPU times: user 8min 2s, sys: 12min 46s, total: 20min 49s\n",
      "Wall time: 4min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# NN\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = MLPClassifier(hidden_layer_sizes=(100,),alpha=.005,solver='sgd',activation='relu',\n",
    "                          max_iter=200,learning_rate='adaptive',learning_rate_init=.01)\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['NN',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7754442649434572 0.7088122605363985 0.329608938547486\n",
      "1 0.728171334431631 0.6923076923076923 0.37988826815642457\n",
      "2 0.7408 0.7058823529411765 0.31843575418994413\n",
      "3 0.7698541329011345 0.7186311787072244 0.29608938547486036\n",
      "4 0.7516129032258064 0.7038461538461539 0.5418994413407822\n",
      "5 0.7454242928452579 0.6630824372759857 0.4748603351955307\n",
      "6 0.7450980392156863 0.7164179104477612 0.5363128491620112\n",
      "7 0.7584 0.7019607843137254 0.4860335195530726\n",
      "8 0.7580645161290323 0.6923076923076923 0.2905027932960894\n",
      "9 0.7223140495867768 0.7163636363636363 0.4245810055865922\n",
      "trn    0.749518\n",
      "tst    0.701961\n",
      "oot    0.407821\n",
      "dtype: float64\n",
      "CPU times: user 3min 38s, sys: 811 ms, total: 3min 39s\n",
      "Wall time: 3min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# GBC\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = GradientBoostingClassifier(learning_rate=0.001,max_depth=15,n_estimators=30, min_samples_split=150, min_samples_leaf=150)\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['GBC',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8746031746031746 0.816 0.553072625698324\n",
      "1 0.865506329113924 0.8145161290322581 0.5418994413407822\n",
      "2 0.8876582278481012 0.8064516129032258 0.5251396648044693\n",
      "3 0.8682432432432432 0.8263888888888888 0.547486033519553\n",
      "4 0.8741721854304636 0.8369565217391305 0.547486033519553\n",
      "5 0.8578352180936996 0.8084291187739464 0.5754189944134078\n",
      "6 0.8629690048939641 0.8014981273408239 0.5307262569832403\n",
      "7 0.8621794871794872 0.78125 0.553072625698324\n",
      "8 0.8817891373801917 0.8110236220472441 0.5698324022346368\n",
      "9 0.8783333333333333 0.775 0.4972067039106145\n",
      "trn    0.871329\n",
      "tst    0.807751\n",
      "oot    0.544134\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Catboost\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = CatBoostClassifier(verbose=0,\n",
    "            iterations=100,\n",
    "#             learning_rate=0.03,\n",
    "#             l2_leaf_reg=5\n",
    "    \n",
    "    )\n",
    "#\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['cat boost',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # XGB\n",
    "\n",
    "# FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "# for niter in range(nitermax):  \n",
    "#     X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "#     model = XGBClassifier(\n",
    "#         booster='gbtree',\n",
    "#         max_depth=5, \n",
    "#         min_child_weight=75,\n",
    "#         sub_sample=75,\n",
    "#         gamma=0.01, \n",
    "#     )\n",
    "\n",
    "#     X_oot = X_oot_orig.copy()\n",
    "#     X_trn_save = X_trn.copy()\n",
    "#     Y_trn_save = Y_trn.copy()\n",
    "\n",
    "#     model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "#     predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "#     X_trn['predicted'] = predictions\n",
    "#     X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "#     topRows = int(round(X_trn.shape[0]*0.03))\n",
    "#     temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_tst)[:,1]\n",
    "#     X_tst['predicted']=predictions\n",
    "#     X_tst['Fraud'] = Y_tst['Fraud']\n",
    "#     topRows = int(round(X_tst.shape[0]*0.03))\n",
    "#     temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_oot)[:,1]\n",
    "#     X_oot['predicted']=predictions\n",
    "#     X_oot['Fraud'] = Y_oot['Fraud']\n",
    "#     topRows = int(round(X_oot.shape[0]*0.03))\n",
    "#     temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "#     print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "#     Modeling_output.iloc[counter] = ['XGB',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "#     counter = counter + 1\n",
    "    \n",
    "# print(FDR3.mean())\n",
    "# model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6811594202898551 0.6563706563706564 0.5363128491620112\n",
      "1 0.6759868421052632 0.6544117647058824 0.5195530726256983\n",
      "2 0.6773675762439807 0.7003891050583657 0.547486033519553\n",
      "3 0.6892561983471074 0.6218181818181818 0.43575418994413406\n",
      "4 0.6846986089644513 0.6523605150214592 0.5251396648044693\n",
      "5 0.6820349761526232 0.6772908366533864 0.49162011173184356\n",
      "6 0.6833602584814217 0.6666666666666666 0.5195530726256983\n",
      "7 0.6650563607085346 0.6911196911196911 0.5307262569832403\n",
      "8 0.6985172981878089 0.6007326007326007 0.39106145251396646\n",
      "9 0.6644951140065146 0.7105263157894737 0.5418994413407822\n",
      "trn    0.680193\n",
      "tst    0.663169\n",
      "oot    0.503911\n",
      "dtype: float64\n",
      "CPU times: user 3min 1s, sys: 6.81 s, total: 3min 8s\n",
      "Wall time: 3min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Knn\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors=300) \n",
    "    \n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['Knn',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # SVM\n",
    "\n",
    "# FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "# for niter in range(nitermax):  \n",
    "#     X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "#     model = svm.SVC(\n",
    "#         C=.1, \n",
    "# #         gamma=100,\n",
    "# #         kernel='linear',\n",
    "#         kernel='poly',\n",
    "#         probability=True)\n",
    "    \n",
    "#     X_oot = X_oot_orig.copy()\n",
    "#     X_trn_save = X_trn.copy()\n",
    "#     Y_trn_save = Y_trn.copy()\n",
    "\n",
    "#     model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "#     predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "#     X_trn['predicted'] = predictions\n",
    "#     X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "#     topRows = int(round(X_trn.shape[0]*0.03))\n",
    "#     temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_tst)[:,1]\n",
    "#     X_tst['predicted']=predictions\n",
    "#     X_tst['Fraud'] = Y_tst['Fraud']\n",
    "#     topRows = int(round(X_tst.shape[0]*0.03))\n",
    "#     temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_oot)[:,1]\n",
    "#     X_oot['predicted']=predictions\n",
    "#     X_oot['Fraud'] = Y_oot['Fraud']\n",
    "#     topRows = int(round(X_oot.shape[0]*0.03))\n",
    "#     temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "#     print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "#     Modeling_output.iloc[counter] = ['SVM',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "#     counter = counter + 1\n",
    "    \n",
    "# print(FDR3.mean())\n",
    "# model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Trn</th>\n",
       "      <th>Tst</th>\n",
       "      <th>OOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log reg</td>\n",
       "      <td>0.640127</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.324022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log reg</td>\n",
       "      <td>0.628019</td>\n",
       "      <td>0.679537</td>\n",
       "      <td>0.318436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log reg</td>\n",
       "      <td>0.654517</td>\n",
       "      <td>0.64257</td>\n",
       "      <td>0.324022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log reg</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.391061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>log reg</td>\n",
       "      <td>0.62623</td>\n",
       "      <td>0.692593</td>\n",
       "      <td>0.324022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model       Trn       Tst       OOT\n",
       "0  log reg  0.640127  0.666667  0.324022\n",
       "1  log reg  0.628019  0.679537  0.318436\n",
       "2  log reg  0.654517   0.64257  0.324022\n",
       "3  log reg  0.653333      0.65  0.391061\n",
       "4  log reg   0.62623  0.692593  0.324022"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Modeling_output.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.640127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.628019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.654517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.653333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.62623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model Type     Value\n",
       "0  log reg  Trn  0.640127\n",
       "1  log reg  Trn  0.628019\n",
       "2  log reg  Trn  0.654517\n",
       "3  log reg  Trn  0.653333\n",
       "4  log reg  Trn   0.62623"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unpivot = df.melt( id_vars='Model', value_vars=['Trn','Tst','OOT'], var_name=['Type'], value_name='Value')\n",
    "df_unpivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.640127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.628019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.654517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.653333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.62623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model Type     Value\n",
       "0  log reg  Trn  0.640127\n",
       "1  log reg  Trn  0.628019\n",
       "2  log reg  Trn  0.654517\n",
       "3  log reg  Trn  0.653333\n",
       "4  log reg  Trn   0.62623"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare = df_unpivot[(df_unpivot['Type']=='Trn') | (df_unpivot['Type']=='Tst') | (df_unpivot['Type']=='OOT')]\n",
    "df_compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Trn</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Tst</th>\n",
       "      <th colspan=\"2\" halign=\"left\">OOT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.772807</td>\n",
       "      <td>0.014695</td>\n",
       "      <td>0.702483</td>\n",
       "      <td>0.012021</td>\n",
       "      <td>0.482123</td>\n",
       "      <td>0.043676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBC</th>\n",
       "      <td>0.750814</td>\n",
       "      <td>0.015834</td>\n",
       "      <td>0.720412</td>\n",
       "      <td>0.031120</td>\n",
       "      <td>0.537430</td>\n",
       "      <td>0.008244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn</th>\n",
       "      <td>0.680193</td>\n",
       "      <td>0.010295</td>\n",
       "      <td>0.663169</td>\n",
       "      <td>0.034106</td>\n",
       "      <td>0.503911</td>\n",
       "      <td>0.051188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM</th>\n",
       "      <td>0.857257</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.801421</td>\n",
       "      <td>0.033241</td>\n",
       "      <td>0.562570</td>\n",
       "      <td>0.009142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>0.711927</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.700389</td>\n",
       "      <td>0.022964</td>\n",
       "      <td>0.527374</td>\n",
       "      <td>0.038902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.774271</td>\n",
       "      <td>0.011930</td>\n",
       "      <td>0.720804</td>\n",
       "      <td>0.023080</td>\n",
       "      <td>0.553631</td>\n",
       "      <td>0.005555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat boost</th>\n",
       "      <td>0.871329</td>\n",
       "      <td>0.009563</td>\n",
       "      <td>0.807751</td>\n",
       "      <td>0.018682</td>\n",
       "      <td>0.544134</td>\n",
       "      <td>0.022532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log reg</th>\n",
       "      <td>0.640927</td>\n",
       "      <td>0.011121</td>\n",
       "      <td>0.662173</td>\n",
       "      <td>0.022294</td>\n",
       "      <td>0.328492</td>\n",
       "      <td>0.022470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Trn                 Tst                 OOT          \n",
       "               mean       std      mean       std      mean       std\n",
       "Model                                                                \n",
       "DT         0.772807  0.014695  0.702483  0.012021  0.482123  0.043676\n",
       "GBC        0.750814  0.015834  0.720412  0.031120  0.537430  0.008244\n",
       "Knn        0.680193  0.010295  0.663169  0.034106  0.503911  0.051188\n",
       "LGBM       0.857257  0.009259  0.801421  0.033241  0.562570  0.009142\n",
       "NN         0.711927  0.015700  0.700389  0.022964  0.527374  0.038902\n",
       "RF         0.774271  0.011930  0.720804  0.023080  0.553631  0.005555\n",
       "cat boost  0.871329  0.009563  0.807751  0.018682  0.544134  0.022532\n",
       "log reg    0.640927  0.011121  0.662173  0.022294  0.328492  0.022470"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = df.groupby('Model').agg({'Trn':['mean','std'],'Tst':['mean','std'],'OOT':['mean','std']})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(20,15))\n",
    "# plt.rcParams.update({'font.size':20})\n",
    "# ax = sns.boxplot(x='Model',y='Trn', data=df, color='navy')\n",
    "\n",
    "# # Select which box you want to change    \n",
    "# mybox = ax.artists[model_counter-1]\n",
    "\n",
    "# # Change the appearance of that box\n",
    "# mybox.set_facecolor('red')\n",
    "# # mybox.set_edgecolor('black')\n",
    "# # mybox.set_linewidth(3)\n",
    "# plt.ylim(0,1)\n",
    "# plt.xlabel('')\n",
    "# plt.ylabel('Train Score (FDR3%)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(20,15))\n",
    "# ax = sns.boxplot(x='Model',y='Tst', data=df, color='navy')\n",
    "\n",
    "# # Select which box you want to change    \n",
    "# mybox = ax.artists[model_counter-1]\n",
    "\n",
    "# # Change the appearance of that box\n",
    "# mybox.set_facecolor('red')\n",
    "# # mybox.set_edgecolor('black')\n",
    "# # mybox.set_linewidth(3)\n",
    "# plt.ylim(0,1)\n",
    "# plt.xlabel('')\n",
    "# plt.ylabel('Test Score (FDR3%)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(20,15))\n",
    "# ax = sns.boxplot(x='Model',y='OOT', data=df, color='navy')\n",
    "\n",
    "# # Select which box you want to change    \n",
    "# mybox = ax.artists[model_counter-1]\n",
    "\n",
    "# # Change the appearance of that box\n",
    "# mybox.set_facecolor('red')\n",
    "# # mybox.set_edgecolor('black')\n",
    "# # mybox.set_linewidth(3)\n",
    "# plt.ylim(0,1)\n",
    "# plt.xlabel('')\n",
    "# plt.ylabel('OOT Score (FDR3%)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,15))\n",
    "# ax = sns.boxplot(x='Model',y='OOT', data=df, color='navy')\n",
    "ax = sns.boxplot(x='Model',y='Value',hue='Type', data=df_compare, palette=['navy','r','g'])\n",
    "# Select which box you want to change    \n",
    "mybox = ax.artists[model_counter-1]\n",
    "\n",
    "# Change the appearance of that box\n",
    "mybox.set_edgecolor('black')\n",
    "# mybox.set_linewidth(3)\n",
    "# plxlabelabel('')\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel('Score (FDR3%)')\n",
    "plt.yticks(np.arange(0,1,.1))\n",
    "plt.grid(axis='y')\n",
    "plt.savefig('modeling.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration:  0:15:43.188944\n"
     ]
    }
   ],
   "source": [
    "print('duration: ', datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the notebook makes the tables for your final model of choice. You need to run that final model only once (no CV). If you want you can run the below cell over and over by itself until it gives you a model you like. But you can't change from your best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7339901477832512 0.7047970479704797 0.5027932960893855\n",
      "1 0.7197452229299363 0.7420634920634921 0.4972067039106145\n",
      "2 0.7222222222222222 0.6993006993006993 0.49162011173184356\n",
      "3 0.7129186602870813 0.7430830039525692 0.4860335195530726\n",
      "4 0.7310126582278481 0.7258064516129032 0.4972067039106145\n",
      "5 0.7302631578947368 0.7463235294117647 0.5027932960893855\n",
      "6 0.7328990228013029 0.6917293233082706 0.49162011173184356\n",
      "7 0.7409733124018838 0.6995884773662552 0.4972067039106145\n",
      "8 0.7287066246056783 0.7398373983739838 0.5027932960893855\n",
      "9 0.7317880794701986 0.7391304347826086 0.5027932960893855\n",
      "10 0.734860883797054 0.7100371747211895 0.5586592178770949\n",
      "11 0.7121464226289518 0.7204301075268817 0.5027932960893855\n",
      "12 0.7266666666666667 0.7428571428571429 0.4972067039106145\n",
      "13 0.7459546925566343 0.6679389312977099 0.4860335195530726\n",
      "14 0.7306451612903225 0.7346153846153847 0.4748603351955307\n",
      "15 0.7298578199052133 0.6842105263157895 0.4972067039106145\n",
      "16 0.7303370786516854 0.6731517509727627 0.49162011173184356\n",
      "17 0.7224025974025974 0.7083333333333334 0.4860335195530726\n",
      "18 0.7095709570957096 0.6897810218978102 0.4860335195530726\n",
      "19 0.7203252032520325 0.7169811320754716 0.4860335195530726\n",
      "20 0.7126805778491172 0.7159533073929961 0.49162011173184356\n",
      "21 0.7108239095315024 0.7011494252873564 0.5586592178770949\n",
      "22 0.7403225806451613 0.6615384615384615 0.5418994413407822\n",
      "23 0.7173553719008264 0.7272727272727273 0.5083798882681564\n",
      "24 0.722662440570523 0.7269076305220884 0.4972067039106145\n",
      "25 0.7371794871794872 0.6796875 0.4972067039106145\n",
      "26 0.727580372250423 0.7197231833910035 0.48044692737430167\n",
      "27 0.739202657807309 0.6510791366906474 0.5363128491620112\n",
      "28 0.7168576104746317 0.7286245353159851 0.4860335195530726\n",
      "29 0.737785016286645 0.7105263157894737 0.4860335195530726\n",
      "trn    0.726991\n",
      "tst    0.710082\n",
      "oot    0.500745\n",
      "dtype: float64\n",
      "CPU times: user 32.5 s, sys: 1.32 s, total: 33.8 s\n",
      "Wall time: 5.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for niter in range(30):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "# here's where you put your final model of choice\n",
    "    model = lgb.LGBMClassifier(num_leaves=3,n_estimators=50)\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['LGBM',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    if(FDR3.loc[niter, 'oot'] > .56): break\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn_eval = X_trn.copy()\n",
    "X_tst_eval = X_tst.copy()\n",
    "X_oot_eval = X_oot.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_zip3_total_7</th>\n",
       "      <th>Merchnum_max_7</th>\n",
       "      <th>card_zip_total_14</th>\n",
       "      <th>card_zip_total_60</th>\n",
       "      <th>merch_zip_max_7</th>\n",
       "      <th>Card_Merchnum_desc_total_60</th>\n",
       "      <th>zip3_total_0</th>\n",
       "      <th>card_merch_total_30</th>\n",
       "      <th>card_zip_total_30</th>\n",
       "      <th>card_merch_total_60</th>\n",
       "      <th>predicted</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90369</th>\n",
       "      <td>7.596835</td>\n",
       "      <td>3.953540</td>\n",
       "      <td>1.268944</td>\n",
       "      <td>1.043352</td>\n",
       "      <td>3.955548</td>\n",
       "      <td>1.107139</td>\n",
       "      <td>1.549789</td>\n",
       "      <td>1.208868</td>\n",
       "      <td>1.179664</td>\n",
       "      <td>1.093740</td>\n",
       "      <td>0.855447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89082</th>\n",
       "      <td>5.336974</td>\n",
       "      <td>2.091614</td>\n",
       "      <td>5.264274</td>\n",
       "      <td>4.639760</td>\n",
       "      <td>2.093019</td>\n",
       "      <td>4.039575</td>\n",
       "      <td>-0.359610</td>\n",
       "      <td>5.100122</td>\n",
       "      <td>5.028220</td>\n",
       "      <td>4.768855</td>\n",
       "      <td>0.754284</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89083</th>\n",
       "      <td>5.429325</td>\n",
       "      <td>2.091614</td>\n",
       "      <td>5.355532</td>\n",
       "      <td>4.721906</td>\n",
       "      <td>2.093019</td>\n",
       "      <td>4.123618</td>\n",
       "      <td>-0.244006</td>\n",
       "      <td>5.189002</td>\n",
       "      <td>5.116125</td>\n",
       "      <td>4.852798</td>\n",
       "      <td>0.754284</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89077</th>\n",
       "      <td>5.289437</td>\n",
       "      <td>2.091614</td>\n",
       "      <td>5.217299</td>\n",
       "      <td>4.597476</td>\n",
       "      <td>2.093019</td>\n",
       "      <td>3.996314</td>\n",
       "      <td>6.434113</td>\n",
       "      <td>5.054370</td>\n",
       "      <td>4.982970</td>\n",
       "      <td>4.725645</td>\n",
       "      <td>0.740270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89074</th>\n",
       "      <td>5.044844</td>\n",
       "      <td>2.091614</td>\n",
       "      <td>4.975602</td>\n",
       "      <td>4.379911</td>\n",
       "      <td>2.093019</td>\n",
       "      <td>3.880173</td>\n",
       "      <td>6.127935</td>\n",
       "      <td>4.818969</td>\n",
       "      <td>4.750152</td>\n",
       "      <td>4.503318</td>\n",
       "      <td>0.740270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89068</th>\n",
       "      <td>4.327532</td>\n",
       "      <td>2.091614</td>\n",
       "      <td>4.266778</td>\n",
       "      <td>3.741861</td>\n",
       "      <td>2.093019</td>\n",
       "      <td>3.227390</td>\n",
       "      <td>5.230011</td>\n",
       "      <td>4.128610</td>\n",
       "      <td>4.067368</td>\n",
       "      <td>3.851305</td>\n",
       "      <td>0.740270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89075</th>\n",
       "      <td>5.161815</td>\n",
       "      <td>2.091614</td>\n",
       "      <td>5.091188</td>\n",
       "      <td>4.483956</td>\n",
       "      <td>2.093019</td>\n",
       "      <td>-0.132462</td>\n",
       "      <td>6.274357</td>\n",
       "      <td>4.931544</td>\n",
       "      <td>4.861492</td>\n",
       "      <td>4.609640</td>\n",
       "      <td>0.727359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89120</th>\n",
       "      <td>6.575506</td>\n",
       "      <td>2.091614</td>\n",
       "      <td>6.488149</td>\n",
       "      <td>5.741435</td>\n",
       "      <td>2.093019</td>\n",
       "      <td>4.754353</td>\n",
       "      <td>1.190770</td>\n",
       "      <td>6.292115</td>\n",
       "      <td>6.207134</td>\n",
       "      <td>5.894639</td>\n",
       "      <td>0.719282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89128</th>\n",
       "      <td>7.085336</td>\n",
       "      <td>2.091614</td>\n",
       "      <td>6.991946</td>\n",
       "      <td>6.194929</td>\n",
       "      <td>2.093019</td>\n",
       "      <td>5.218319</td>\n",
       "      <td>1.828970</td>\n",
       "      <td>6.782789</td>\n",
       "      <td>6.692423</td>\n",
       "      <td>6.358058</td>\n",
       "      <td>0.719282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89121</th>\n",
       "      <td>6.972016</td>\n",
       "      <td>2.091614</td>\n",
       "      <td>6.879966</td>\n",
       "      <td>6.094131</td>\n",
       "      <td>2.093019</td>\n",
       "      <td>5.115193</td>\n",
       "      <td>1.687117</td>\n",
       "      <td>6.673726</td>\n",
       "      <td>6.584557</td>\n",
       "      <td>6.255053</td>\n",
       "      <td>0.719282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89117</th>\n",
       "      <td>6.489780</td>\n",
       "      <td>2.091614</td>\n",
       "      <td>6.403438</td>\n",
       "      <td>5.665182</td>\n",
       "      <td>2.093019</td>\n",
       "      <td>4.676339</td>\n",
       "      <td>1.083459</td>\n",
       "      <td>6.209610</td>\n",
       "      <td>6.125534</td>\n",
       "      <td>5.816717</td>\n",
       "      <td>0.719282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87173</th>\n",
       "      <td>3.322467</td>\n",
       "      <td>1.704384</td>\n",
       "      <td>0.547739</td>\n",
       "      <td>0.394158</td>\n",
       "      <td>1.705664</td>\n",
       "      <td>0.442953</td>\n",
       "      <td>0.518808</td>\n",
       "      <td>0.506450</td>\n",
       "      <td>0.484953</td>\n",
       "      <td>0.430338</td>\n",
       "      <td>0.717390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89114</th>\n",
       "      <td>6.389830</td>\n",
       "      <td>2.091614</td>\n",
       "      <td>6.304671</td>\n",
       "      <td>5.576276</td>\n",
       "      <td>2.093019</td>\n",
       "      <td>4.585380</td>\n",
       "      <td>0.958343</td>\n",
       "      <td>6.113416</td>\n",
       "      <td>6.030396</td>\n",
       "      <td>5.725866</td>\n",
       "      <td>0.717091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89130</th>\n",
       "      <td>9.181526</td>\n",
       "      <td>5.575067</td>\n",
       "      <td>9.063329</td>\n",
       "      <td>8.059490</td>\n",
       "      <td>5.577600</td>\n",
       "      <td>7.043212</td>\n",
       "      <td>4.452956</td>\n",
       "      <td>8.800213</td>\n",
       "      <td>8.687710</td>\n",
       "      <td>8.263425</td>\n",
       "      <td>0.712376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89186</th>\n",
       "      <td>9.842442</td>\n",
       "      <td>5.575067</td>\n",
       "      <td>9.716424</td>\n",
       "      <td>8.647376</td>\n",
       "      <td>5.577600</td>\n",
       "      <td>7.579095</td>\n",
       "      <td>5.280284</td>\n",
       "      <td>9.436295</td>\n",
       "      <td>9.316813</td>\n",
       "      <td>8.864176</td>\n",
       "      <td>0.712376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89183</th>\n",
       "      <td>9.795480</td>\n",
       "      <td>5.575067</td>\n",
       "      <td>9.670017</td>\n",
       "      <td>8.605603</td>\n",
       "      <td>5.577600</td>\n",
       "      <td>7.536357</td>\n",
       "      <td>5.221497</td>\n",
       "      <td>9.391098</td>\n",
       "      <td>9.272112</td>\n",
       "      <td>8.821489</td>\n",
       "      <td>0.712376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89174</th>\n",
       "      <td>9.385836</td>\n",
       "      <td>5.575067</td>\n",
       "      <td>9.265221</td>\n",
       "      <td>8.241225</td>\n",
       "      <td>5.577600</td>\n",
       "      <td>7.163565</td>\n",
       "      <td>4.708710</td>\n",
       "      <td>8.996846</td>\n",
       "      <td>8.882187</td>\n",
       "      <td>8.449136</td>\n",
       "      <td>0.712376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89129</th>\n",
       "      <td>7.176237</td>\n",
       "      <td>2.091614</td>\n",
       "      <td>7.081771</td>\n",
       "      <td>6.275786</td>\n",
       "      <td>2.093019</td>\n",
       "      <td>-0.049739</td>\n",
       "      <td>1.942758</td>\n",
       "      <td>6.870274</td>\n",
       "      <td>6.778948</td>\n",
       "      <td>6.440684</td>\n",
       "      <td>0.705743</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89134</th>\n",
       "      <td>9.253586</td>\n",
       "      <td>5.575067</td>\n",
       "      <td>9.134536</td>\n",
       "      <td>8.123588</td>\n",
       "      <td>5.577600</td>\n",
       "      <td>0.015838</td>\n",
       "      <td>4.543160</td>\n",
       "      <td>8.869565</td>\n",
       "      <td>8.756302</td>\n",
       "      <td>8.328925</td>\n",
       "      <td>0.698643</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89091</th>\n",
       "      <td>5.769437</td>\n",
       "      <td>2.091614</td>\n",
       "      <td>5.691619</td>\n",
       "      <td>5.024436</td>\n",
       "      <td>2.093019</td>\n",
       "      <td>0.711174</td>\n",
       "      <td>0.181742</td>\n",
       "      <td>5.516334</td>\n",
       "      <td>5.439865</td>\n",
       "      <td>5.161949</td>\n",
       "      <td>0.693109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       card_zip3_total_7  Merchnum_max_7  card_zip_total_14  \\\n",
       "90369           7.596835        3.953540           1.268944   \n",
       "89082           5.336974        2.091614           5.264274   \n",
       "89083           5.429325        2.091614           5.355532   \n",
       "89077           5.289437        2.091614           5.217299   \n",
       "89074           5.044844        2.091614           4.975602   \n",
       "89068           4.327532        2.091614           4.266778   \n",
       "89075           5.161815        2.091614           5.091188   \n",
       "89120           6.575506        2.091614           6.488149   \n",
       "89128           7.085336        2.091614           6.991946   \n",
       "89121           6.972016        2.091614           6.879966   \n",
       "89117           6.489780        2.091614           6.403438   \n",
       "87173           3.322467        1.704384           0.547739   \n",
       "89114           6.389830        2.091614           6.304671   \n",
       "89130           9.181526        5.575067           9.063329   \n",
       "89186           9.842442        5.575067           9.716424   \n",
       "89183           9.795480        5.575067           9.670017   \n",
       "89174           9.385836        5.575067           9.265221   \n",
       "89129           7.176237        2.091614           7.081771   \n",
       "89134           9.253586        5.575067           9.134536   \n",
       "89091           5.769437        2.091614           5.691619   \n",
       "\n",
       "       card_zip_total_60  merch_zip_max_7  Card_Merchnum_desc_total_60  \\\n",
       "90369           1.043352         3.955548                     1.107139   \n",
       "89082           4.639760         2.093019                     4.039575   \n",
       "89083           4.721906         2.093019                     4.123618   \n",
       "89077           4.597476         2.093019                     3.996314   \n",
       "89074           4.379911         2.093019                     3.880173   \n",
       "89068           3.741861         2.093019                     3.227390   \n",
       "89075           4.483956         2.093019                    -0.132462   \n",
       "89120           5.741435         2.093019                     4.754353   \n",
       "89128           6.194929         2.093019                     5.218319   \n",
       "89121           6.094131         2.093019                     5.115193   \n",
       "89117           5.665182         2.093019                     4.676339   \n",
       "87173           0.394158         1.705664                     0.442953   \n",
       "89114           5.576276         2.093019                     4.585380   \n",
       "89130           8.059490         5.577600                     7.043212   \n",
       "89186           8.647376         5.577600                     7.579095   \n",
       "89183           8.605603         5.577600                     7.536357   \n",
       "89174           8.241225         5.577600                     7.163565   \n",
       "89129           6.275786         2.093019                    -0.049739   \n",
       "89134           8.123588         5.577600                     0.015838   \n",
       "89091           5.024436         2.093019                     0.711174   \n",
       "\n",
       "       zip3_total_0  card_merch_total_30  card_zip_total_30  \\\n",
       "90369      1.549789             1.208868           1.179664   \n",
       "89082     -0.359610             5.100122           5.028220   \n",
       "89083     -0.244006             5.189002           5.116125   \n",
       "89077      6.434113             5.054370           4.982970   \n",
       "89074      6.127935             4.818969           4.750152   \n",
       "89068      5.230011             4.128610           4.067368   \n",
       "89075      6.274357             4.931544           4.861492   \n",
       "89120      1.190770             6.292115           6.207134   \n",
       "89128      1.828970             6.782789           6.692423   \n",
       "89121      1.687117             6.673726           6.584557   \n",
       "89117      1.083459             6.209610           6.125534   \n",
       "87173      0.518808             0.506450           0.484953   \n",
       "89114      0.958343             6.113416           6.030396   \n",
       "89130      4.452956             8.800213           8.687710   \n",
       "89186      5.280284             9.436295           9.316813   \n",
       "89183      5.221497             9.391098           9.272112   \n",
       "89174      4.708710             8.996846           8.882187   \n",
       "89129      1.942758             6.870274           6.778948   \n",
       "89134      4.543160             8.869565           8.756302   \n",
       "89091      0.181742             5.516334           5.439865   \n",
       "\n",
       "       card_merch_total_60  predicted  Fraud  \n",
       "90369             1.093740   0.855447      1  \n",
       "89082             4.768855   0.754284      1  \n",
       "89083             4.852798   0.754284      1  \n",
       "89077             4.725645   0.740270      1  \n",
       "89074             4.503318   0.740270      1  \n",
       "89068             3.851305   0.740270      1  \n",
       "89075             4.609640   0.727359      1  \n",
       "89120             5.894639   0.719282      1  \n",
       "89128             6.358058   0.719282      1  \n",
       "89121             6.255053   0.719282      1  \n",
       "89117             5.816717   0.719282      1  \n",
       "87173             0.430338   0.717390      0  \n",
       "89114             5.725866   0.717091      1  \n",
       "89130             8.263425   0.712376      1  \n",
       "89186             8.864176   0.712376      1  \n",
       "89183             8.821489   0.712376      1  \n",
       "89174             8.449136   0.712376      1  \n",
       "89129             6.440684   0.705743      1  \n",
       "89134             8.328925   0.698643      1  \n",
       "89091             5.161949   0.693109      1  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['bin','#recs','#g','#b','%g','%b','tot','cg','cb','%cg','FDR','KS','FPR']\n",
    "FDR_trn = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "FDR_tst = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "FDR_oot = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "trn_sorted = X_trn_eval.sort_values('predicted',ascending=False)\n",
    "tst_sorted = X_tst_eval.sort_values('predicted',ascending=False)\n",
    "oot_sorted = X_oot_eval.sort_values('predicted',ascending=False)\n",
    "bad_tot_trn = sum(X_trn_eval.loc[:, 'Fraud'])\n",
    "bad_tot_tst = sum(X_tst_eval.loc[:, 'Fraud'])\n",
    "bad_tot_oot = sum(X_oot_eval.loc[:, 'Fraud'])\n",
    "num_tot_trn = len(X_trn_eval)\n",
    "num_tot_tst = len(X_tst_eval)\n",
    "num_tot_oot = len(X_oot_eval)\n",
    "good_tot_trn = num_tot_trn - bad_tot_trn\n",
    "good_tot_tst = num_tot_tst - bad_tot_tst\n",
    "good_tot_oot = num_tot_oot - bad_tot_oot\n",
    "oot_sorted.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin</th>\n",
       "      <th>#recs</th>\n",
       "      <th>#g</th>\n",
       "      <th>#b</th>\n",
       "      <th>%g</th>\n",
       "      <th>%b</th>\n",
       "      <th>tot</th>\n",
       "      <th>cg</th>\n",
       "      <th>cb</th>\n",
       "      <th>%cg</th>\n",
       "      <th>FDR</th>\n",
       "      <th>KS</th>\n",
       "      <th>FPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>59.504132</td>\n",
       "      <td>40.495868</td>\n",
       "      <td>121.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.604128</td>\n",
       "      <td>27.374302</td>\n",
       "      <td>26.770173</td>\n",
       "      <td>1.469388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>76.859504</td>\n",
       "      <td>23.140496</td>\n",
       "      <td>242.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.384460</td>\n",
       "      <td>43.016760</td>\n",
       "      <td>41.632299</td>\n",
       "      <td>2.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>91.735537</td>\n",
       "      <td>8.264463</td>\n",
       "      <td>363.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.315825</td>\n",
       "      <td>48.603352</td>\n",
       "      <td>46.287527</td>\n",
       "      <td>3.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>95.867769</td>\n",
       "      <td>4.132231</td>\n",
       "      <td>484.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>3.289142</td>\n",
       "      <td>51.396648</td>\n",
       "      <td>48.107506</td>\n",
       "      <td>4.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11613.0</td>\n",
       "      <td>11435.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>95.947307</td>\n",
       "      <td>99.441341</td>\n",
       "      <td>3.494034</td>\n",
       "      <td>64.241573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.173554</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>11734.0</td>\n",
       "      <td>11555.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>96.954187</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.045813</td>\n",
       "      <td>64.553073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11855.0</td>\n",
       "      <td>11676.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>97.969458</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.030542</td>\n",
       "      <td>65.229050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11976.0</td>\n",
       "      <td>11797.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>98.984729</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.015271</td>\n",
       "      <td>65.905028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12097.0</td>\n",
       "      <td>11918.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.581006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bin  #recs     #g    #b          %g         %b      tot       cg  \\\n",
       "0      0.0    0.0    0.0   0.0    0.000000   0.000000      0.0      0.0   \n",
       "1      1.0  121.0   72.0  49.0   59.504132  40.495868    121.0     72.0   \n",
       "2      2.0  121.0   93.0  28.0   76.859504  23.140496    242.0    165.0   \n",
       "3      3.0  121.0  111.0  10.0   91.735537   8.264463    363.0    276.0   \n",
       "4      4.0  121.0  116.0   5.0   95.867769   4.132231    484.0    392.0   \n",
       "..     ...    ...    ...   ...         ...        ...      ...      ...   \n",
       "96    96.0  121.0  121.0   0.0  100.000000   0.000000  11613.0  11435.0   \n",
       "97    97.0  121.0  120.0   1.0   99.173554   0.826446  11734.0  11555.0   \n",
       "98    98.0  121.0  121.0   0.0  100.000000   0.000000  11855.0  11676.0   \n",
       "99    99.0  121.0  121.0   0.0  100.000000   0.000000  11976.0  11797.0   \n",
       "100  100.0  121.0  121.0   0.0  100.000000   0.000000  12097.0  11918.0   \n",
       "\n",
       "        cb         %cg         FDR         KS        FPR  \n",
       "0      0.0    0.000000    0.000000   0.000000   0.000000  \n",
       "1     49.0    0.604128   27.374302  26.770173   1.469388  \n",
       "2     77.0    1.384460   43.016760  41.632299   2.142857  \n",
       "3     87.0    2.315825   48.603352  46.287527   3.172414  \n",
       "4     92.0    3.289142   51.396648  48.107506   4.260870  \n",
       "..     ...         ...         ...        ...        ...  \n",
       "96   178.0   95.947307   99.441341   3.494034  64.241573  \n",
       "97   179.0   96.954187  100.000000   3.045813  64.553073  \n",
       "98   179.0   97.969458  100.000000   2.030542  65.229050  \n",
       "99   179.0   98.984729  100.000000   1.015271  65.905028  \n",
       "100  179.0  100.000000  100.000000   0.000000  66.581006  \n",
       "\n",
       "[101 rows x 13 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(101):\n",
    "    percent_rows_trn = int(round(X_trn_eval.shape[0]*0.01*i))\n",
    "    percent_rows_tst = int(round(X_tst_eval.shape[0]*0.01*i))\n",
    "    percent_rows_oot = int(round(X_oot_eval.shape[0]*0.01*i))\n",
    "    temp_trn = trn_sorted.head(percent_rows_trn)\n",
    "    temp_tst = tst_sorted.head(percent_rows_tst)\n",
    "    temp_oot = oot_sorted.head(percent_rows_oot)\n",
    "    num_bad_trn = sum(temp_trn.loc[:,'Fraud'])\n",
    "    num_bad_tst = sum(temp_tst.loc[:,'Fraud'])\n",
    "    num_bad_oot = sum(temp_oot.loc[:,'Fraud'])\n",
    "    num_tot_trn = len(temp_trn)\n",
    "    num_tot_tst = len(temp_tst)\n",
    "    num_tot_oot = len(temp_oot)\n",
    "    num_good_trn = num_tot_trn - num_bad_trn\n",
    "    num_good_tst = num_tot_tst - num_bad_tst\n",
    "    num_good_oot = num_tot_oot - num_bad_oot\n",
    "    \n",
    "    FDR_trn.loc[i, 'bin'] = i\n",
    "    FDR_trn.loc[i,'#recs'] = 0\n",
    "    FDR_trn.loc[i, 'tot'] = num_tot_trn\n",
    "    FDR_trn.loc[i, 'cg'] = num_good_trn\n",
    "    FDR_trn.loc[i, 'cb'] = num_bad_trn\n",
    "    FDR_tst.loc[i, 'bin'] = i\n",
    "    FDR_tst.loc[i, 'tot'] = num_tot_tst\n",
    "    FDR_tst.loc[i, 'cg'] = num_good_tst\n",
    "    FDR_tst.loc[i, 'cb'] = num_bad_tst\n",
    "    FDR_oot.loc[i, 'bin'] = i\n",
    "    FDR_oot.loc[i, 'tot'] = num_tot_oot\n",
    "    FDR_oot.loc[i, 'cg'] = num_good_oot\n",
    "    FDR_oot.loc[i, 'cb'] = num_bad_oot\n",
    "    if i != 0:\n",
    "        FDR_trn.loc[i, '#g'] = num_good_trn - FDR_trn.loc[i-1, 'cg']\n",
    "        FDR_trn.loc[i, '#b'] = num_bad_trn - FDR_trn.loc[i-1, 'cb']\n",
    "        FDR_trn.loc[i,'#recs'] = FDR_trn.loc[i, '#g'] + FDR_trn.loc[i, '#b']\n",
    "        FDR_trn.loc[i, '%g'] = 100* (num_good_trn - FDR_trn.loc[i-1, 'cg']) / (num_tot_trn - FDR_trn.loc[i-1, 'tot'])\n",
    "        FDR_trn.loc[i, '%b'] = 100 - FDR_trn.loc[i, '%g']\n",
    "        FDR_trn.loc[i, '%cg'] = 100 * num_good_trn / good_tot_trn\n",
    "        FDR_trn.loc[i, 'FDR'] = 100 * num_bad_trn / bad_tot_trn\n",
    "        FDR_trn.loc[i, 'KS'] = FDR_trn.loc[i, 'FDR'] - FDR_trn.loc[i, '%cg']\n",
    "        FDR_trn.loc[i, 'FPR'] = num_good_trn / num_bad_trn\n",
    "        FDR_tst.loc[i, '#g'] = num_good_tst - FDR_tst.loc[i-1, 'cg']\n",
    "        FDR_tst.loc[i, '#b'] = num_bad_tst - FDR_tst.loc[i-1, 'cb']\n",
    "        FDR_tst.loc[i,'#recs'] = FDR_tst.loc[i, '#g'] + FDR_tst.loc[i, '#b']\n",
    "        FDR_tst.loc[i, '%g'] = 100* (num_good_tst - FDR_tst.loc[i-1, 'cg']) / (num_tot_tst - FDR_tst.loc[i-1, 'tot'])\n",
    "        FDR_tst.loc[i, '%b'] = 100 - FDR_tst.loc[i, '%g']\n",
    "        FDR_tst.loc[i, '%cg'] = 100 * num_good_tst / good_tot_tst\n",
    "        FDR_tst.loc[i, 'FDR'] = 100 * num_bad_tst / bad_tot_tst\n",
    "        FDR_tst.loc[i, 'KS'] = FDR_tst.loc[i, 'FDR'] - FDR_tst.loc[i, '%cg']\n",
    "        FDR_tst.loc[i, 'FPR'] = num_good_tst / num_bad_tst\n",
    "        FDR_oot.loc[i, '#g'] = num_good_oot - FDR_oot.loc[i-1, 'cg']\n",
    "        FDR_oot.loc[i, '#b'] = num_bad_oot - FDR_oot.loc[i-1, 'cb']\n",
    "        FDR_oot.loc[i,'#recs'] = FDR_oot.loc[i, '#g'] + FDR_oot.loc[i, '#b']\n",
    "        FDR_oot.loc[i, '%g'] = 100* (num_good_oot - FDR_oot.loc[i-1, 'cg']) / (num_tot_oot - FDR_oot.loc[i-1, 'tot'])\n",
    "        FDR_oot.loc[i, '%b'] = 100 - FDR_oot.loc[i, '%g']\n",
    "        FDR_oot.loc[i, '%cg'] = 100 * num_good_oot / good_tot_oot\n",
    "        FDR_oot.loc[i, 'FDR'] = 100 * num_bad_oot / bad_tot_oot\n",
    "        FDR_oot.loc[i, 'KS'] = FDR_oot.loc[i, 'FDR'] - FDR_oot.loc[i, '%cg']\n",
    "        FDR_oot.loc[i, 'FPR'] = num_good_oot / num_bad_oot\n",
    "\n",
    "FDR_oot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR3.to_csv('FDR3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR_trn.to_csv('FDR_trn.csv', index=False)\n",
    "FDR_tst.to_csv('FDR_tst.csv', index=False)\n",
    "FDR_oot.to_csv('FDR_oot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration:  0:15:49.088942\n"
     ]
    }
   ],
   "source": [
    "print(\"duration: \", datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
